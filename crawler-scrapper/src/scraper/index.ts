// For more information, see https://crawlee.dev/
import { CheerioCrawler, ProxyConfiguration, Configuration } from 'crawlee';
import { testConnection, syncDatabase } from '../database/config.js';
import { initializeModels } from '../database/models/index.js';

// DÃ©sactiver complÃ¨tement les logs de Crawlee
Configuration.getGlobalConfig().set('logLevel', 'ERROR');

import { router } from './mangaScraperRoutes.js';

const startUrls = ['https://www.nautiljon.com/mangas/gachiakuta.html'];
const startUrls2 = ['https://www.nautiljon.com/mangas/twin+star+exorcists.html'];

const crawler = new CheerioCrawler({
    // proxyConfiguration: new ProxyConfiguration({ proxyUrls: ['...'] }),
    requestHandler: router,

    // Comment this option to scrape the full website.
    // maxRequestsPerCrawl: 100,

    // Ajouter un dÃ©lai entre les requÃªtes pour ne pas surcharger le site
    requestHandlerTimeoutSecs: 60,

    maxConcurrency: 1, // Limiter le nombre de requÃªtes simultanÃ©es

    // DÃ©lai entre les requÃªtes (en millisecondes)
    maxRequestRetries: 3,

    // Configuration des timeouts
    navigationTimeoutSecs: 30,
});

// Fonction principale avec initialisation de la base de donnÃ©es
async function main() {
    console.log('ğŸš€ DÃ©marrage de l\'application...');
    
    // Initialiser la connexion Ã  la base de donnÃ©es
    const isConnected = await testConnection();
    if (!isConnected) {
        console.error('âŒ Impossible de se connecter Ã  la base de donnÃ©es. ArrÃªt de l\'application.');
        process.exit(1);
    }
    
    // Initialiser les modÃ¨les
    await initializeModels();
    
    // Synchroniser la base de donnÃ©es (crÃ©er les tables si elles n'existent pas)
    await syncDatabase();
    
    console.log('ğŸ•·ï¸ DÃ©marrage du crawler...');
    
    // Lancer le crawler
    await crawler.run(startUrls);
    
    console.log('âœ… Scraping terminÃ© avec succÃ¨s!');
}

// Lancer l'application
main().catch((error) => {
    console.error('âŒ Erreur fatale:', error);
    process.exit(1);
});
